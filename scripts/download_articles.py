# download_articles.py
import os
import requests

def download_pdfs(links_file, output_dir=os.path.expanduser("~/chatbot_env/data_sources/articles")):
    os.makedirs(output_dir, exist_ok=True)
    
    with open(links_file, "r", encoding="utf-8") as f:
        links = [line.strip() for line in f if line.strip()]
    
    success, failed = 0, 0
    for idx, url in enumerate(links):
        try:
            print(f"â¬‡ï¸ [{idx+1}/{len(links)}] Ø¯Ø± Ø­Ø§Ù„ Ø¯Ø§Ù†Ù„ÙˆØ¯: {url}")
            response = requests.get(url, timeout=20)
            response.raise_for_status()

            filename = f"article_{idx+1:03d}.pdf"
            filepath = os.path.join(output_dir, filename)

            with open(filepath, "wb") as pdf_file:
                pdf_file.write(response.content)

            print(f"âœ… Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {filepath}")
            success += 1
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø§Ù†Ù„ÙˆØ¯ {url} --> {e}")
            failed += 1

    print("\n--- Ø®Ù„Ø§ØµÙ‡ ---")
    print(f"ğŸ“¦ Ù…ÙˆÙÙ‚: {success}")
    print(f"ğŸš« Ù†Ø§Ù…ÙˆÙÙ‚: {failed}")
    print(f"ğŸ“ Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± Ù¾ÙˆØ´Ù‡: {output_dir}")

if __name__ == "__main__":
    download_pdfs("article_links.txt")
