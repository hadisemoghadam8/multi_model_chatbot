import json
import os

# Ù…Ø³ÛŒØ±Ù‡Ø§
INPUT_FILE = "processed_chunks/chunks.jsonl"
OUTPUT_FILE = "processed_chunks/cleaned_chunks.jsonl"

# Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ù…Ø´Ú©ÙˆÚ© (Ù‚Ø§Ø¨Ù„ Ú¯Ø³ØªØ±Ø´)
BAD_CHARS = ["ï¿½", "\u200c", "\u200e", "\u202a", "\u202c"]  # ZWNJØŒ RTLØŒ LRM...

def count_bad_chars(text):
    return sum(text.count(char) for char in BAD_CHARS)

def is_valid_chunk(text):
    reasons = []
    words = text.strip().split()
    
    if len(words) < 30:
        reasons.append("Ø®ÛŒÙ„ÛŒ Ú©ÙˆØªØ§Ù‡ Ø¨ÙˆØ¯ (<Û³Û° Ú©Ù„Ù…Ù‡)")
    
    bad_char_count = count_bad_chars(text)
    if bad_char_count > 3:
        reasons.append(f"Ú©Ø§Ø±Ø§Ú©ØªØ±Ù‡Ø§ÛŒ Ù…Ø´Ú©ÙˆÚ© Ø²ÛŒØ§Ø¯ Ø¯Ø§Ø´Øª ({bad_char_count})")
    
    return len(reasons) == 0, reasons

def filter_chunks(input_file, output_file):
    total = 0
    kept = 0
    removed = 0

    with open(input_file, "r", encoding="utf-8") as fin, \
         open(output_file, "w", encoding="utf-8") as fout:
        
        for line in fin:
            total += 1
            chunk = json.loads(line)
            text = chunk.get("text", "")

            valid, reasons = is_valid_chunk(text)
            if valid:
                fout.write(json.dumps(chunk, ensure_ascii=False) + "\n")
                kept += 1
            else:
                removed += 1
                print(f"â›” Ø­Ø°Ù Ø´Ø¯: chunk_id={chunk.get('chunk_id')} | Ø¯Ù„Ø§ÛŒÙ„: {'ØŒ '.join(reasons)}")

    print("\n--- Ø®Ù„Ø§ØµÙ‡ ---")
    print(f"âœ… Ù†Ú¯Ù‡ Ø¯Ø§Ø´ØªÙ‡â€ŒØ´Ø¯Ù‡: {kept}")
    print(f"âŒ Ø­Ø°Ùâ€ŒØ´Ø¯Ù‡: {removed}")
    print(f"ğŸ“¦ Ù…Ø¬Ù…ÙˆØ¹ Ú†Ø§Ù†Ú©â€ŒÙ‡Ø§: {total}")
    print(f"ğŸ“ Ø®Ø±ÙˆØ¬ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯ Ø¯Ø±: {output_file}")

if __name__ == "__main__":
    filter_chunks(INPUT_FILE, OUTPUT_FILE)
